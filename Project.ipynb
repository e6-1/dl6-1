{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as pylab\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imageio.core.util import asarray as imgToArr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videoFile = './data/driving.avi'\n",
    "vid = imageio.get_reader(videoFile,  'ffmpeg')\n",
    "\n",
    "# Columns: Frame, Clutch, Brake, AccPed, GazeX, GazeY, heading, Speed, HeadRate, Accel\n",
    "dataFile = './data/actions.csv'\n",
    "df = pd.read_csv(dataFile, delimiter='\\t')\n",
    "\n",
    "# One-hot encode brakes\n",
    "outputs = OneHotEncoder(sparse=False).fit_transform(df['Brake'].reshape(-1,1))  # column 0: no brake, column 1: brake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def minibatch(data, batch_size, data_size):\n",
    "    \"\"\"Generates a minibatch from the given data and parameters.\"\"\"\n",
    "    randomized = np.random.permutation(data)\n",
    "    batches = []\n",
    "    num_batches = 0\n",
    "    while num_batches * batch_size < data_size:\n",
    "        new_batch = randomized[num_batches * batch_size:(num_batches + 1) * batch_size]\n",
    "        batches.append(new_batch)\n",
    "        num_batches += 1\n",
    "    return batches\n",
    "\n",
    "def get_glimpses(images, coords):\n",
    "    \"\"\"Gets a batch of glimpses.\"\"\"\n",
    "    arr = []\n",
    "    for img, coord in zip(images, coords):\n",
    "        arr.append(get_glimpse(img, coord[0], coord[1]))\n",
    "    return np.array(arr)\n",
    "\n",
    "def get_glimpse(image, x, y, stride=14):\n",
    "    \"\"\"Returns a subsection (glimpse) of the image centered on the given point.\"\"\"\n",
    "    x = int(x)  # Force to int\n",
    "    y = int(y)  # Force to int\n",
    "    min_x = x - stride\n",
    "    max_x = x + stride\n",
    "    \n",
    "    min_y = y - stride\n",
    "    max_y = y + stride\n",
    "    image_glimpse = image[min_y:max_y, min_x:max_x, :]  # NOTE: row, column, RGB\n",
    "#     image_glimpse = image[min_y:max_y, min_x:max_x, 0]  # NOTE: row, column, RGB; everything is greyscale; flatten RGB layer\n",
    "    return imgToArr(image_glimpse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define TensorFlow computation graph\n",
    "\n",
    "\"\"\"Create a logistic regression model for brake classification with 28x28x3 image input.\"\"\"\n",
    "# Create placeholders for inputs that will be placed via batches\n",
    "image_input = tf.placeholder(tf.float32, [None, 28*28*3], name=\"image\")\n",
    "gaze_input = tf.placeholder(tf.float32, [None, 2], name=\"gaze\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 2], name=\"output\")\n",
    "\n",
    "image_weights = tf.Variable(tf.truncated_normal([28*28*3, 2], stddev=1), name=\"image_weights\")\n",
    "gaze_weights = tf.Variable(tf.truncated_normal([2, 2], stddev=1), name=\"gaze_weights\")\n",
    "\n",
    "image_bias = tf.Variable(tf.truncated_normal([2], stddev=1), name=\"image_bias\")\n",
    "gaze_bias = tf.Variable(tf.truncated_normal([2], stddev=1), name=\"gaze_bias\")\n",
    "\n",
    "image_logits = tf.matmul(image_input, image_weights) + image_bias\n",
    "gaze_logits = tf.matmul(gaze_input, gaze_weights) + gaze_bias\n",
    "\n",
    "logits = tf.mul(tf.add(image_logits, gaze_logits), 0.5)\n",
    "y = tf.nn.softmax(logits)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.reduce_sum(-y_*tf.log(tf.clip_by_value(y, 1e-10,1.0)),reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "# initialization of variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \"\"\"Trains a model.\"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        for epoch in range(100):\n",
    "            epochs = minibatch(range(100), 25, 100)\n",
    "\n",
    "            for index_batch in epochs:\n",
    "                index_batch = index_batch.tolist()\n",
    "                frames = df['Frame'][index_batch].astype(np.int32)\n",
    "                gaze_xs = df['GazeX'][index_batch]\n",
    "                gaze_ys = df['GazeY'][index_batch]\n",
    "\n",
    "                # Image is 900x244, so bound the gaze to get full 28x28 blocks\n",
    "                if any(gaze_xs < 14) or any(gaze_xs > 900-14):\n",
    "                    continue\n",
    "                if any(gaze_ys < 14) or any(gaze_ys > 244-14):\n",
    "                    continue\n",
    "\n",
    "                gazes = np.array([gaze_xs, gaze_ys]).T\n",
    "                output = outputs[index_batch]\n",
    "                images = [vid.get_data(frame) for frame in frames]\n",
    "                glimpses = get_glimpses(images, gazes)\n",
    "                glimpses = glimpses.reshape(-1, 28*28*3)\n",
    "\n",
    "                sess.run(optimizer, feed_dict={image_input: glimpses, gaze_input: gazes, y_: output})\n",
    "                ce = sess.run(cross_entropy, feed_dict={image_input: glimpses, gaze_input: gazes, y_: output})\n",
    "                print(ce)\n",
    "    #             if index == 67:\n",
    "    #                 fig = pylab.figure()\n",
    "    #                 pylab.imshow(this_glimpse)\n",
    "    #                 pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.1048\n",
      "22.1048\n",
      "22.1048\n",
      "22.1048\n",
      "22.1048\n",
      "20.2627\n",
      "22.1048\n",
      "20.2627\n",
      "17.4996\n",
      "20.2627\n",
      "21.1838\n",
      "22.1048\n",
      "19.3417\n",
      "19.3417\n",
      "20.2627\n",
      "16.5786\n",
      "14.7365\n",
      "17.0973\n",
      "14.7365\n",
      "14.7365\n",
      "15.6576\n",
      "17.4996\n",
      "15.6576\n",
      "13.8155\n",
      "12.8945\n",
      "11.0524\n",
      "15.4858\n",
      "11.0524\n",
      "6.44724\n",
      "11.9734\n",
      "9.21034\n",
      "10.0018\n",
      "8.28931\n",
      "9.21034\n",
      "4.60517\n",
      "3.68414\n",
      "11.9734\n",
      "3.68414\n",
      "7.36827\n",
      "7.36827\n",
      "5.5262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-20edab97d712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-86a1b2e9019d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mgazes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgaze_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_ys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mglimpses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_glimpses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mglimpses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglimpses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-86a1b2e9019d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mgazes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgaze_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_ys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mglimpses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_glimpses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mglimpses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglimpses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ethan/.local/lib/python3.5/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkClosed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BaseReaderWriter_last_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Image tests im and meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ethan/.local/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ethan/.local/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_read_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;31m# t0 = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ethan/.local/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_read_frame_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_catcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_n_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m                 \u001b[0;31m# Check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ethan/.local/lib/python3.5/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mread_n_bytes\u001b[0;34m(f, N)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mextra_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
